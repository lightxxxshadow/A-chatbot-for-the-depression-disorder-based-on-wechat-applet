# 量表问题匹配  
## 实现原理  
  根据用户回复选择合适的量表问题，实现方法：  
  
  首先将二十个问题与用户回复进行分词，去除停用词后每一句都变成了一串关键词的组合，再根据wiki中文百科数据训练一个word2vec模型，利用该模型对每个关键词都进行向量转化，并计算每个用户回复关键词与sds问题关键词的
余弦相似度。由于反义仍代表其具有相关性，故对余弦相似度取绝对值并储存。  

  最后采用如下策略选定最终sds问题：  
  
  对每个sds问题，将用户回复的每个关键词分别与该sds问题的所有关键词相似度相比较取并最大值储存，作为该sds问题下用户该关键词的得分。将每个前述得分进行求均值作为该sds问题的得分（注意没有对应向量的特殊情况），选择分数最高的sds问题即可。  
  
## 具体实现  

首先[在这里](https://pan.baidu.com/s/1fknK52heQbfsXURt9uqlrg)下载中文维基百科训练而成的word2vec模型，放在sds_match文件夹下，运行sds_match.py文件，运行sds_match函数即可，该函数需要传入一个参数，即为待匹配sds问题的语句，返回值为sds量表20个问题的对应序号。  

# 量表问题选择  
## 实现原理  
  在获得对应问题序号后从改写的sds问题库中随机选取对应问题的六个重述之一进行回复，下次进入sds模式时便接着上次选择重述问题，以此在保证科学性的前提下尽可能的具有回复的多样性。  
  
## 具体实现  

利用简单的随机数即可实现。

# 量表得分获取  

## 实现原理  

首先针对20个sds问题各自的四个回复选项，如：从不、偶尔、经常、一直等，分别编写可能的具有相同含义的用户回复模拟语句（对应着1、2、3、4分数即类别标签），同时编写可能的用户不进行正面的回答的回复模拟（对应着一种额外的类别标签5），利用数据增强将数据进行扩容并打乱。利用预训练的bert模型将文本向量化，接上一层全连接层并利用前述语料进行五分类模型的训练，训练出20个分类器。最后进行判断：  

若属于第5类即未正面回复的概率最大，则不进行分数计算，继续进行该sds问题的追问，利用下一句重述重新询问该问题，若仍不符合，则放弃该问题的询问。反之，则判断是否有除第五类外类别的概率大于75%，若有，返回该类别（即对应得分），若无，则进行下列计算：  

取概率最大的两个类别，依照概率进行加权，乘以对应分数并求和，返回该值作为分数。

## 具体实现

在[该网站](https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip)下载bert中文预训练模型并放在sds_get_score目录下，dataset中已给出sds问题一分类器的训练语料示例，在modeling中将transformer的默认隐藏层大小减至256，transformer层数与注意力头削减至6，增大dropout率至0.15，以减小模型规模以应对较小的数据量。运行run.sh脚本文件开始模型的训练，随后在dataset下test文件中按格式写入待分类语句，运行predict.sh脚本开始预测（可通过修改脚本文件进行超参数包括模型及预测文件位置的修改）。若判断为正面回复，随后运行get_scores.py获取该问题得分，compute_accuracy_predict.py用于计算计算测试集准确度。  

# 思考  

1.在长时间判断用户情感倾向较负面时开始进入sds模式，时刻进行匹配度计算，若高于某阈值则直接进行提问，否则20句后将直接进行匹配，选择最高的问题进行提问。随时间增加，由于剩下问题被问到几率越来越小，故可考虑阈值将随时间减小，以降低匹配要求。  

2.对已问过的问题，可以不完全将其设置为不可再问，为其设置较大阈值即可，因考虑到多次回答同一问题可能更准确。（待探讨，感觉不太行）
